## Quick Background: TensorFlow

TensorFlow is an open source software library released in 2015 by Google to
make it easier for developers to design, build, and train deep learning models.
TensorFlow originated as an internal library that Google developers used to
build models in-house.

Starting in 2011, Google Brain built DistBelief as their first-generation,
proprietary, machine learning system (specillaly designed for Deep Learning, a 
branch of Machine Learning). TensorFlow was Google Brain's second generation 
machine learning system, which was released as open source on November 9, 2015. 
While the reference implementation runs on single devices, TensorFlow can run 
on multiple CPUs and GPUs (with optional CUDA extensions).

At a high level, TensorFlow is a Python library that allows users to express
arbitrary computation as a graph of data flows.

## Why is important TensorFlow in a Big Data ecosystem?

TensorFlow is basically a software library for numerical computation. We could
include this tool in the segment of Octave, Scilab, R or Pandas. Traditionally
this kind of tools are used in Hight Performance Computing (or Grid Computing)
environments, on top or resource managers such as SGE, HTCondor or SLURM.

Nevertheless Big Data and HPC are hand by hand related, the more data we
collect, the more computational capacity we need to analyze the data.
Machine learning is well suited to the complexity of dealing with disparate
data sources and the huge variety of variables and amounts of data involved. 

With machine learning we need computation power and massive data processing
(data driven), this is a kind of technology where massive CPU power and massive
data I/O converge together.

## Getting started with TensorFlow


``````
``````
## TensorFlow in Containers (Docker)

## TensorFlow in OpenShift
